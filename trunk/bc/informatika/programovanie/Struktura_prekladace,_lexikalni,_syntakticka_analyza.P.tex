\subsection{Struktura pøekladaèe, lexikální, syntaktická analıza}

Zdroj: poznámky a slidy z pøednášek Principy pøekladaèù Dr. J. Yaghoba

\subsubsection*{Pøekladaèe}

\begin{e}{Definice}{0}{Pøekladaè}
Formální definice: \emph{pøekladaè} je zobrazení $L_{in}\to L_{out}$ pro nìjaké dva jazyky $L_{in},L_{out}$, vstupní generovanı gramatikou $G_{in}$, vıstupní generovanı gramatikou $G_{out}$ nebo pøijímanı automatem $A_{out}$. Je to takové zobrazení, kde $\forall w\in L_{in}\ \exists w'\in L_{out}$. Pro $w\notin L_{in}$ zobrazení neexistuje.

Neformálnì jde o stroj, kterı nìjakı zdrojovı kód (v nìjakém zdrojovém jazyce) pøevádí na cílovı kód (v cílovém jazyce) a pøípadnì vypisuje chybová hlášení.

Definice neøíká nic o tøídách jazykù a gramatik, ve kterıch pøekladaè operuje. Bìné programovací jazyky jsou \uv{plus minus} bezkontextové -- nebo se na bezkontextové pøevádìjí, aby byly rozpoznatelné nìèím prakticky implementovatelnım (tedy zásobníkovım automatem, Turingovy stroje jsou ponìkud sloité).
\end{e}


\begin{e}{Pøíklady}{0}{0}
Pøíklady pouití pøekladaèù:
\begin{pitemize}
    \item (pøekvapivì) pøeklad programù, psanıch v nìjakém vyšším programovacím jazyce, do strojového kódu cílové platformy
    \item syntax-highlighting (vìtšinou lexikálnì øízenı)
    \item pretty printer
    \item statické kontroly programu (hledání chyb bez spouštìní programù)
    \item interpretery (napø. skriptovacích jazykù, run-time moduly pro interpretované jazyky jako je Java)
    \item databázové stroje, dotazovací jazyky
\end{pitemize}
\end{e}


\begin{obecne}{Pøeklad programu}
Program (pro jednoduchost jedinı modul) se 
\begin{penumerate}
    \item ze zdrojového kódu v nìjakém programovacím jazyce \emph{preprocesorem} (co je taky pøekladaè, upravující zdrojovı kód na textové úrovni) pøevede na textovı soubor (pøipravenı pro další pøeklad),
    \item \emph{pøekladaèem} se pøevede dál do assemblerového kódu (jde o kód v jiném jazyce, mnohem bliším cílové architektuøe -- jde o textovı popis instrukcí procesoru),
    \item \emph{assemblerem} se pøevádí na \uv{object-file} -- modul, ve kterém u jazyk odpovídá strojovému kódu cílové CPU,
    \item nakonec \emph{linker}, resp. \emph{loader} pøipojí další informace a vytvoøí finální spustitelnı kód.
\end{penumerate}
\end{obecne}

\begin{obecne}{Fáze pøekladu pøekladaèem}
Tradiènì se pøekladaèe dìlí na dvì fáze -- \emph{front-end} a \emph{back-end}. První z nich je zamìøená hlavnì na analızu zdrojového kódu po lexikální a syntaktické stránce a její pøevod do nìjakého mezikódu, tj. pøípravu pro back-end. Úkolem back-endu je pak z pøedpøipravené formy vygenerovat finální kód v cílovém jazyce.

První fáze se dále dìlí na tyto èásti:
\begin{penumerate}
    \item \emph{lexikální analıza} -- pøevádí vstupní text do binární formy, na sled identifikátorù a konstant; hodnoty objektù ukládá do spec. tabulek 
    \item \emph{syntaktická analıza} -- abstraktní èást, nezajímá se o hodnoty a vıznam elementù jazyka, úkolem je rozpoznat, zda vstupní slovo (vstup) patøí do jazyka; v dnešních pøekladaèích staví tzv. \uv{syntaktickı strom} kódu
    \item \emph{sémantická analıza} -- zkoumá sémantiku (vıznam, smysl) elementù jazyka (napø. u sèítání promìnnıch kontrola typù, pouívání definovanıch promìnnıch atd.)
    \item \emph{generování mezikódu} -- úzce svázané se sémantickou analızou, naèítá hodnoty lexikálních elementù z tabulek a vytváøí binární formu kódu, v ideálním pøípadì nezávislou na vstupním ani vıstupním jazyce
    \item \emph{optimalizace nad mezikódem} -- díky pøekladu do nìjakého abstraktního mezikódu lze nad ním potom provádìt rùzné obecné (teoreticky dokázané) optimalizace, aby byl vıslednı kód ekvivalentní s pùvodním, ale rychlejší pøi provádìní cílovım strojem
\end{penumerate}

Backend má na starosti hlavnì
\begin{penumerate}
    \item \emph{generování kódu} -- vytváøí u kód pro konkrétní cílovı stroj / architekturu / CPU. 
    \item \emph{optimalizace nízkoúrovòového kódu} -- optimalizace, zamìøené na vlastnosti konkrétních CPU a cílovı jazyk (tj. takové, které nad obecnım mezikódem s vysokou abstrakcí provést nejde)
\end{penumerate}

Všechny fáze pøekladaèe (vìtšinou, kdy se pominou tøeba staší verze GCC a podobnì) sdílejí jednotné \emph{tabulky symbolù} -- hodnot lexikálních elementù a jinıch vìcí a obsluhu chyb. Pøekladaè musí rozpoznat všechny chyby, ale bez velké èasové reie, navíc nesmí mít falešné poplachy. Taky by nemìl vyrábìt chyby sám ;-).

V døívìjších pøekladaèích se vstupní kód procházel nìkolikrát, protoe nebylo technicky moné ho udret celı v pamìti. Dnes je potøeba vìtšinou jen jeden pøechod, ale nìkdy je nutnıch víc (napø. dopøedné skoky v assembleru -- nevím ještì jak daleko skáèu).
\end{obecne}

\begin{e}{Poznámka}{0}{Syntax-driven compilation}
Nejdùleitìjší èástí dnešních pøekladaèù bıvá syntaktická analıza; provádí se èasto najednou se sémantickou analızou a generováním mezikódu -- vše mívá na starosti jedinı zásobníkovı automat. Navíc si èasto sám vyvolává lexikální analızu, ta je jím tedy øízená, take se taková technika oznaèuje \emph{syntaxí øízenı pøeklad}.
\end{e}

\begin{obecne}{Automatické generování (èástí) pøekladaèe}
Protoe dnešní programovací jazyky jsou relativnì sloité (gramatiky které je generují mají øádovì stovky pøepisovacích pravidel), konstrukce automatù pøijímajících takové jazyky \uv{ruènì} je pøíliš nároèná. Proto existují nástroje, které generují nìkteré èásti pøekladaèe -- generátor lexikálních analyzátorù -- \uv{scannerù} -- (popíšu lexikální elementy a struktury a co s nimi dìlá a vypadne mi analyzátor jako kód v jazyce C) je napø. \emph{Flex}, pro vırobu parserù (syntaktickıch analyzátorù) z popisu gramatiky slouí napø. \emph{Bison}, \emph{Coco/R} nebo \emph{ANTLR}. Nìkteré známé pøekladaèe mají ale i tak ruènì generované parsery (GCC).

Existují i generátory generátorù kódu (ale jejich ménì, protoe to je dost sloité) -- pro popis vıstupního CPU dostanu z instrukèního mezikódu kód pøímo pro nìj. Instrukèní mezikód mùe bıt pro více architektur úplnì stejnı. Pøíkladem tohoto je \emph{Mono JIT Compiler}.
\end{obecne}


\begin{obecne}{Mezikód}
(Vysokoúrovòovı) \emph{mezikód} je vlastnì jakési rozhraní pro pøechod (rozdìlení i spolupráci) mezi front-endem a back-endem. Jde o binární reprezentaci zdrojového kódu, má bıt nezávislı na vstupním i vıstupním jazyce. Pokud tomu tak je, je moné napø. kombinovat rùzné back-endy a front-endy, jako tomu je u GCC (více back-endù pro 1 front-end) nebo .NET (více front-endù). Vìtšinou ale je mezikód o nìco posunutı buï více k závislosti na back-endu nebo na front-endu.

Mezikód je moné reprezentovat nìkolika zpùsoby -- napø. syntaktickım stromem (vhodné v pamìti), postfixovım zápisem (linearizace stromu) nebo tøíadresovım kódem (lineární, sekvence pøíkazù $x:= y\ \mathrm{op}\ z$).
\end{obecne}

\begin{obecne}{Graf toku øízení}
Graf toku øízení je graf, vytváøenı pøekladaèi (vìtš. pro 1 funkci) za úèelem optimalizací a také generování vısledného kódu. Uzly -- \emph{základní bloky} -- jsou nepøerušované vıpoèty (bez instrukcí skokù a bez cílù skokù uvnitø blokù), z nich první instrukce bıvá cílem skoku nebo vstupním bodem funkce. Hrany pak reprezentují skoky -- pro podmínìné skoky a case pøíkazy pak z uzlù vede více hran.
\end{obecne}

\subsubsection*{Lexikální analıza}

\begin{e}{Definice}{0}{Lexikální analıza}
Lexikální analıza je èást pøekladaèe, zodpovìdná za rozpoznávání jednotlivıch nedìlitelnıch elementù zdrojového jazyka (napø. klíèová slova, identifikátory, závorky atd.) a jejich pøevod na nìjakou binární reprezentaci, vhodnou pro syntaktickou analızu (napø. uloení názvù identifikátorù do tabulek symbolù). V zásadì jde o rozpoznávání regulárních vırazù. Historicky šlo o provedení analızy na celém zdrojáku a pøeposlání do další fáze, dnes je vìtšinou ovládaná ze syntaktické analızy (opakované volání \uv{vra další element}). Slouí také ke zvìtšení \uv{vıhledu} dalších fází (jedním elementem pøestává bıt jeden znak, je jím jeden element vstupního jazyka).
\end{e}

\begin{e}{Definice}{0}{Token, pattern}
\emph{Token} je vıstup lexikální analızy -- jeden nedìlitelnı element zdrojového jazyka. Je zároveò vstupem syntaktické analızy (tam se nazıvá \emph{terminál}). Lexikální analıza uvauje mnoinu øetìzcù, které produkují pro syntaktickou analızu stejnı token (napø. díky ignore-caseovosti nebo jako dùsledek slouèení všech øetìzcovıch nebo èíselnıch konstant pod stejnı token, protoe s nimi je dále nakládáno bez ohledu na hodnotu). Mnoina øetìzcù, produkujících danı token, se popisuje urè. pravidly -- \emph{patternem}, kde se obvykle uívá regulárních vırazù.
\end{e}

\begin{e}{Definice}{0}{Lexém}
\emph{Lexém} neboli \emph{lexikální element} je sekvence znakù ve zdrojovém kódu, která (vìtšinou) odpovídá nìjakému patternu nìjakého tokenu. Napø. komentáøe ale jako svùj vıstup ádnı token nemají.
\end{e}

\begin{e}{Definice}{0}{Literál}
\emph{Literál} je konstanta ve vstupním jazyce -- má svoji hodnotu (atribut), ukládanou do tabulek symbolù.
\end{e}

\begin{e}{Poznámka}{0}{Atributy tokenù}
Je-li jeden token rozpoznáván více patterny, nebo je-li to literál, má nìjaké další atributy (vìtšinou jenom jeden), které jeho vıznam upøesòují -- napø. token \uv{relaèní operátor} má zpøesnìní \uv{menší nebo rovno}, token \uv{èíselnı literál} má zpøesnìní \uv{12345}.
\end{e}

\begin{obecne}{Problémy lex. analızy}
Mezi nìkteré problémy, které syntaktická analıza musí øešit, patøí
\begin{pitemize}
    \item Poèítání zarovnání -- nìkteré jazyky (Python) mají zarovnání na øádce jako svoji syntaktickou konstrukci
    \item Identifikátory s mezerami (rozlišit identifikátor od jiné konstrukce, i víceslovné)
    \item Klíèová slova jako identifikátory (nìkdy se mohou pøekrıvat)
    \item Kontextovì závislé tokeny -- token závisí na jinıch informacích (napø. \texttt{a*b;} v C -- jde o násobení, nebo deklaraci pointerové promìnné), tady je nutné tokeny sluèovat pro oba vıznamy ???
\end{pitemize}
\end{obecne}

\begin{obecne}{Pozadí lex. analızy}
Na pozadí lexikálního analyzátoru vìtšinou pracuje nìjakı koneènı automat (protoe rozpoznávání regulárních vırazù -- hodnotou reg. vırazu je reg. jazyk -- je práce pro koneèné automaty). Po kadém rozpoznaném tokenu je potøeba automat uvést zpìt do vıchozího stavu.
\end{obecne}

\begin{obecne}{Lexikální chyby}
Chyba v lexikální analıze nastane tehdy, kdy koneènı automat nemùe pokraèovat dál a není v koncovém stavu (napø. pokud nalezne neplatnı znak, nebo neukonèenı øetìzec na konci øádky apod.). Vìtšina lexikálních analyzátorù (pomineme Turbo Pascal ;-)) by mìla bıt schopna nìjakého \uv{rozumného} zotavení z chyby -- vypsat chybu a domyslet chybìjící znak nebo neplatnı znak ignorovat apod., tj. nezastavit se na první chybì. I logické zotavení mùe ale scanner úplnì rozhodit a ten pak vyhazuje nesmyslné chyby. Je také spousta chyb, které lexikální analıza nepozná a projeví se a u syntaktické analızy, napø. \texttt{beign} místo \texttt{begin}, chápané jako identifikátor. 
\end{obecne}

\begin{e}{Poznámka}{0}{Bufferování vstupu}
Syntaktická analıza èasovì zabere cca 60-80\% pøekladu, take se pro její urychlení pouívá bufferování -- neète se po znacích, ale o nìco napøed. Problémem pak jsou napø. \texttt{\#include} direktivy (jsou-li ve vstupním jazyce) -- v okamiku vloení jiného souboru je scanner v nìjakém stavu apod.; scannery musí mít pak monost pøepínat mezi více vstupními soubory (manipulovat s nìkolika buffery).
\end{e}

\subsubsection*{Syntaktická analıza}

\begin{e}{Definice}{0}{Syntaktická analıza}
Syntaktická analıza je èást pøekladaèe, zodpovìdná za:
\begin{penumerate}
    \item rozhodnutí, zda dané slovo (vstup) patøí do zpracovávaného jazyka
    \item syntaxí øízenı pøeklad
    \item stavbu derivaèního stromu (nalezení pøepisovacích pravidel ze startovacího neterminálu gramatiky na vstupní posloupnost tokenù -- terminálù)
\end{penumerate}

Vìtšina programovacích jazykù je bezkontextová, proto je syntaktická analıza pøedstavována zásobníkovım automatem. Syntaktická analıza operuje s gramatikou daného jazyka (snaí se o pøepis abstraktních neterminálù na terminály -- tokeny jazyka).
\end{e}

\begin{e}{Definice}{0}{Derivaèní strom}
Derivaèní strom je \uv{grafická} reprezentace slova vstupního jazyka, nebo spíše derivací, které bylo potøeba provést, aby se v gramatice startovací symbol pøepsal na dané slovo (posloupnost terminálù). Uzly takového grafu jsou neterminály i terminály gramatiky jazyka (v listech ale jsou jen terminály, ve vnitøních uzlech neterminály). Hrany grafu pøedstavují pøepsání podle pravidla gramatiky -- vedou od neterminálu kterı se pøepisuje, ke všem neterminálùm nebo terminálùm na které se pøepisuje (mluvíme o bezkontextovıch gramatikách, take na levé stranì stojí jen jeden neterminál).

Pøepsání v gramatice bohuel nemusí bıt jednoznaèné (tj. pro stejnou posloupnost neterminálù existuje více platnıch derivaèních stromù). Pøikladem je problém \uv{dangling else} z jazykù typu Pascal nebo C -- mám-li za sebou 2x \texttt{if-then} a pak jedno \texttt{else}, nemusí bıt (z gramatiky) jasné, ke kterému \texttt{if-then} ono \texttt{else} patøí. Takové problémy lze (a je nutné) odstranit pøevodem na jednoznaènou gramatiku (napø. pøes další neterminál).
\end{e}

\begin{obecne}{Levá rekurze, levá faktorizace, nebezkontextovost}
Levá rekurze v gramatice se objevuje, pokud je v ní neterminál $A$, pro kterı platí $A\Rightarrow^{*} A\alpha$ pro nìjaké $\alpha\neq\lambda$. Tj. pøes $A$ je moné projít kolikrát chci a vytvoøit posloupnost $\alpha\alpha\dots$. Pokud parser zaèíná u startovacího neterminálu a hledá derivace na na terminály \uv{shora dolù} (to jeden z druhù scannerù dìlá), neví jakou hloubku rekurze má pouít. Proto je nutné i levou rekurzi, stejnì jako nejednoznaènosti, z gramatiky napøed odstranit její úpravou (zde opìt pomùe pøechod pøes novı neterminál).

Problémem je i levá faktorizace -- pøípad, kdy se v gramatice vyskytují pravidla jako $A\to \alpha\beta$ a zároveò $A\to \alpha\gamma$. I ten je moné øešit úpravou gramatiky (pøenos rozhodnutí na pozdìjší dobu, kdy bude známo, kterı ze symbolù $\beta,\gamma$ si vybrat).

Mùe se také i pro bìné konstrukce z programovacích jazykù stát, e nevyhovují bezkontextovım gramatikám -- napø. kontrola deklarace identifikátoru pøed pouitím, kontrola poètu parametrù funkce apod. Zde syntaktická analıza bezkontextovım zpùsobem nestaèí a tyto pøípady je tøeba øešit jinak.
\end{obecne}

\begin{e}{Definice}{0}{Názvosloví gramatik, FIRST a FOLLOW}
Gramatiky se v teorii pøekladaèù oznaèují dvìma a tøemi znaky a èíslem v závorce, obecnì ve tvaru $PXY(k)$, kde:
\begin{pitemize}
    \item $X$ je smìr ètení vstupu (V našem pøípadì vdy $L$, tj. zleva doprava),
    \item $Y$ jsou druhy derivace ($L$ – levé, $R$ – pravé derivace),
    \item $P$ oznaèuje prefix (ještì jemnìjší dìlení na tøídy u nìkterıch gramatik) a
    \item $k$ pøedstavuje \emph{vıhled} (lookahead), kadı parser toti vidí jen na jeden nebo nìkolik tokenù dopøedu a další neuvauje. Obvykle je to celé èíslo, vìtšinou 1, ale také 0 nebo obecnì $k$.
\end{pitemize}
Pøíklady: $LL(1), LR(0), LR(1), LL(k), SLR(1), LALR(1)$

Mnoiny \emph{FIRST} a \emph{FOLLOW} pøedstavují mnoinu pouitelnıch neterminálù na urè. místech (zaèátky øetìzcù derivovanıch z nìjakého pravidla, resp. øetìzce které mohou následovat po nìjakém neterminálu) a pouívají se pro konstrukci parserovıch automatù pro nìjakou gramatiku.
\end{e}

TODO: formalizovat FIRST a FOLLOW, neni to moc slozite?

\begin{e}{Definice}{0}{Analıza shora dolù}
Analıza shora dolù je technika parserù, kdy se parser snaí najít nejlevìjší derivaci pro vstupní øetìzec. Pokouší se tedy zkonstruovat derivaèní strom pro danı vstup poèínaje koøenem a pøidáváním uzlù do stromu -- rozhoduje se, podle kterého pravidla gramatiky pøepíše. Pravidlo pro odstranìní nejednoznaènosti je provádìní \emph{jen levıch derivací}, proto pak automatùm vadí levá rekurze a musí se odstraòovat. Techniky pro nalezení pøepisovacího pravidla jsou:
\begin{pitemize}
    \item \emph{Rekurzivní sestup} pomocí procedur -- pro kadı neterminál existuje jedna procedura, která se rozhodne, které pravidlo pouije na základì vıhledu. Pro rozhodování se sestavují mnoiny FIRST a FOLLOW kadého neterminálu. Potom musí zkontrolovat, jestli pravá strana tohoto pravidla odpovídá vstupu (pøièem vıskyt neterminálu na pravé stranì znamená zavolání jemu pøíslušné procedury).     
    \item \emph{Nerekurzivní analıza s predikcí} -- je implementováno automatem s explicitním zásobníkem: ten má \emph{parsovací tabulku}, která se liší podle gramatiky (sama práce automatu je vdy stejná) -- jsou v ní øádky odpovídající neterminálùm a sloupce terminálùm, v políèkách jsou pøepisovací pravidla  nebo chyby. Na zásobník automatu se ukládají symboly gramatiky a ze vstupu se ètou (lineárnì terminály). V kadém kroku se automat rozhodne podle vstupu a vrcholu zásobníku -- je-li tam terminál, vyhodí se a ukazatel vstupu se posune (nebo se skonèí); je-li na zásobníku neterminál, rozhoduje se podle tabulky (poloka urèená vstupem a neterminálem, buïto se pouije pøepisovací pravidlo nebo skonèí chybou). Konstrukce tabulky je opìt závislá na mnoinách FIRST a FOLLOW.
\end{pitemize}
Analıza shora dolù je pouívána v parserech jednoduchıch jazykù ($LL(1)$ gramatiky s øešením konfliktù zvìtšením vıhledu na $k$ terminálù) -- v generátorech parserù ANTLR a Coco/R, napøíklad.
\end{e}

\begin{e}{Definice}{0}{Analıza zdola nahoru, LR automat}
Parsery s analızou zdola nahoru se pokoušejí najít pozpátku nejpravìjší derivaci pro vstupní øetìzec -- zkonstruovat derivaèní strom pro danı vstup poèínaje listy a stavìním zespodu a po koøen stromu. V jednom redukèním kroku je tak podøetìzec odpovídající pravé stranì pravidla gramatiky nahrazen neterminálem z levé strany pravidla. Analıza zdola nahoru se pouívá ve napø. v generátoru parserù Bison -– je schopná vytvoøit parsery pro $LALR(1), GLR(1)$ gramatiky, které jsou oproti $LL(1)$ parserùm \uv{silnìjší} (Tøída rozpoznávanıch jazykù LR(1) je vlastní nadmnoina LL(1)), všechny bìné programovací jazyky zapsatelné bezkontextovou gramatikou sem patøí. Navíc se dá implementovat zhruba stejnì efektivnì jako metoda shora dolù.

V analıze zdola nahoru se pouívá nìjakı zásobníkovı automat (\emph{LR automat}) ètoucí ze vstupu, parametrizovanı tabulkami \emph{ACTION} a \emph{GOTO}. Na zásobníku se pak uchovávají stavy a symboly gramatiky (nebo jen stavy). Vrchol zásobníku pøedstavuje aktuální stav. V poèáteèní konfiguraci je pointer vstupu nastavenı na zaèátek a na zásobníku je poèáteèní stav. V kadém kroku podle stavu a tokenu na vstupu adresuji tabulku ACTION a získám akci k provedení:
\begin{pitemize}
    \item \emph{SHIFT} $s$ -- posune vstup o 1 terminál, kterı pøidá na zásobník spolu s novım stavem $s$.
    \item \emph{REDUCE} $A\to\alpha$ -- zruší ze zásobníku tolik dvojic stavù a symbolù, jak dlouhé je $\alpha$, na zásobník dá $A$ a stav, kterı najde v tabulce GOTO na pozici odpovídající neterminálu $A$ a aktuálnímu stavu
    \item \emph{ACCEPT} -- generuje nìjakı vıstup, slovo je úspìšnì rozpoznáno
    \item \emph{ERROR} -- zahlásí chybu
\end{pitemize}
V LR automatech v klidu projdou i gramatiky s levou rekurzí. Obecnì se v nich pouívají nìjaké $LR(k)$ gramatiky, vìtšinou \uv{rozšíøené} -- doplnìné o \uv{teèky}, ukazatele pozice v pravidlech, které pomáhají s rozpoznáním konce vstupu. Ke konstrukci tabulek ACTION a GOTO jsou opìt potøeba mnoiny FIRST a FOLLOW, nyní rozšíøené na $k$ symbolù.
\end{e}


TODO: pøidat popis LR(1) a LALR(1) gramatik?
